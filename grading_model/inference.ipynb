{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5720d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/users/scratch1/s189737/collaborative-learning-diabetic-retinopathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecf696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segmentation.dataset import DRSegmentationDataset\n",
    "from segmentation.unet import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "from grading_model.grading_model import GradingModel\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DRSegmentationDataset(\"/users/scratch1/s189737/collaborative-learning-diabetic-retinopathy/datasets/processed_segmentation_dataset/test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "                      test_dataset, \n",
    "                      batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ee527",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model = UNet(3, 5)\n",
    "segmentation_model.to(device)\n",
    "segmentation_model.load_state_dict(torch.load(\"/users/scratch1/s189737/collaborative-learning-diabetic-retinopathy/models/segmentation/pretrained/unet_pretrained.pth\", weights_only=True, map_location=device))\n",
    "\n",
    "grading_model = GradingModel()\n",
    "grading_model.to(device)\n",
    "grading_model.load_state_dict(torch.load(\"/users/scratch1/s189737/collaborative-learning-diabetic-retinopathy/models/classification/grading_model_with_masks_23-07-25_14-08.pth\", weights_only=True, map_location=device))\n",
    "\n",
    "grading_model_pretrained = GradingModel()\n",
    "grading_model_pretrained.to(device)\n",
    "grading_model_pretrained.load_state_dict(torch.load(\"/users/scratch1/s189737/collaborative-learning-diabetic-retinopathy/models/classification/grading_model_pretrained.pth\", weights_only=False, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99820634",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.eval()\n",
    "loss = torch.nn.BCELoss()\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch_id, test_batch in enumerate(test_dataloader):                \n",
    "        input_tensor = test_batch[0].to(device)\n",
    "        target_tensor = test_batch[1].to(device)\n",
    "\n",
    "        val_output = segmentation_model(input_tensor)\n",
    "\n",
    "        loss_value = loss(val_output, target_tensor)\n",
    "        test_loss += loss_value.item() \n",
    "\n",
    "mean_test_loss = test_loss / len(test_dataloader)\n",
    "print(\"Mean test loss:\", mean_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deebf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_index = 1\n",
    "\n",
    "for test_batch_id, (input_batch, target_batch) in enumerate(test_dataloader):\n",
    "    if test_batch_id >= 5:\n",
    "        break\n",
    "\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    masks = segmentation_model(input_batch)\n",
    "    pretrained_logits, pretrained_f_low, pretrained_f_high, _ = grading_model_pretrained(input_batch)\n",
    "\n",
    "    logits, _, _, attention_maps = grading_model(input_batch, masks, pretrained_f_low, pretrained_f_high)\n",
    "\n",
    "    reference_image = input_batch[0].cpu().detach().numpy()\n",
    "    reference_image = reference_image.transpose(1, 2, 0)\n",
    "\n",
    "    target_image = target_batch[0, lesion_index].cpu().detach().numpy()\n",
    "\n",
    "    # TODO: Add min max scaling\n",
    "    reference_image = (reference_image - reference_image.min()) / (reference_image.max() - reference_image.min())\n",
    "    reference_image = (reference_image * 255).astype('uint8')\n",
    "    \n",
    "    attention_map = attention_maps[0, lesion_index].cpu().detach().numpy()\n",
    "    # attention_map = torch.nn.functional.sigmoid(attention_map)\n",
    "    attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())\n",
    "    attention_map = np.where(attention_map > 0.6, 1, 0)\n",
    "    attention_map = (attention_map * 255).astype('uint8')\n",
    "\n",
    "    mask = masks[0][lesion_index].cpu().detach().numpy()\n",
    "    mask = (mask*255).astype('uint8')\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.subplots_adjust(bottom=0.1, right=0.8, top=2)\n",
    "\n",
    "    ax = fig.add_subplot(1,4,1)\n",
    "    ax.imshow(reference_image, cmap='gray')\n",
    "    ax.set_title(\"Wej≈õciowy obraz\")\n",
    "    ax.axis('off')\n",
    "    pos1 = ax.get_position()\n",
    "\n",
    "    ax = fig.add_subplot(1,4,2)\n",
    "    ax.imshow(target_image, cmap='gray')\n",
    "    ax.set_title(\"Maska poprawna\")\n",
    "    ax.axis('off')\n",
    "    pos2 = ax.get_position()\n",
    "\n",
    "    ax = fig.add_subplot(1,4,3)\n",
    "    ax.imshow(attention_map, cmap='gray')\n",
    "    ax.set_title(\"Mapa atencji\")\n",
    "    ax.axis('off')\n",
    "    pos3 = ax.get_position()\n",
    "\n",
    "    ax = fig.add_subplot(1,4,4)\n",
    "    ax.imshow(mask, cmap='gray')\n",
    "    ax.set_title(\"Maska generatora\")\n",
    "    ax.axis('off')\n",
    "    pos4 = ax.get_position()\n",
    "\n",
    "    fig.add_artist(Line2D([pos1.x1, pos1.x1], [pos1.y0, pos1.y1], color='white', linewidth=2))\n",
    "\n",
    "    fig.add_artist(Line2D([pos2.x1, pos2.x1], [pos2.y0, pos2.y1], color='white', linewidth=2))\n",
    "    fig.add_artist(Line2D([pos3.x1, pos3.x1], [pos3.y0, pos3.y1], color='white', linewidth=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
